# HPO Training Profile
# Used alongside the 'model' config during Vizier trials.
# Designed for speed: fewer epochs, tighter early stopping, partial data usage.

# Hardware & Loader Parameters
batch_size: 128
val_batch_size_multiplier: 10
num_workers: 8
pin_memory: true

# Trainer Parameters
max_epochs: 20                    # Increased from 15 for harder leakage-free task
gradient_clip_val: 0.1
limit_train_batches: 0.7          # 70% of data â€” more representative trial eval
precision: "bf16-mixed"
accelerator: "auto"
devices: 1
enable_model_summary: false       # Reduce log noise in trials

# Early Stopping (Aggressive)
early_stopping_patience: 5
early_stopping_min_delta: 1e-4

# TensorBoard (inherits bucket from infra config)
tensorboard_log_dir: "gs://mlops-artifacts-realtime-headway-prediction/tensorboard_logs"