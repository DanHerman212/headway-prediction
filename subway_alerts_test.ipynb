{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb984bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtfs-realtime-bindings\n",
      "  Using cached gtfs_realtime_bindings-2.0.0-py3-none-any.whl.metadata (650 bytes)\n",
      "Requirement already satisfied: protobuf in /Users/danherman/miniconda3/envs/dev/lib/python3.11/site-packages (4.25.3)\n",
      "Using cached gtfs_realtime_bindings-2.0.0-py3-none-any.whl (5.3 kB)\n",
      "Installing collected packages: gtfs-realtime-bindings\n",
      "Successfully installed gtfs-realtime-bindings-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gtfs-realtime-bindings protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12add2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status: 200\n",
      "Successfully fetched 368 alerts.\n",
      "Sample Alert:\n",
      "{'id': 'lmm:alert:496244', 'alert': {'activePeriod': [{'start': '1767371924', 'end': '1767372519'}], 'informedEntity': [{'agencyId': 'MTASBWY', 'routeId': '1'}, {'agencyId': 'MTASBWY', 'stopId': '125'}], 'headerText': {'translation': [{'text': 'Uptown [1] trains are running with delays after NYPD conducted an investigation at 59 St-Columbus Circle.', 'language': 'en'}, {'text': '<p>Uptown [1] trains are running with delays after NYPD conducted an investigation at <b>59 St-Columbus Circle</b>.</p>', 'language': 'en-html'}]}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "url = \"https://api-endpoint.mta.info/Dataservice/mtagtfsfeeds/camsys%2Fsubway-alerts\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    print(f\"Response Status: {response.status_code}\")\n",
    "    \n",
    "    # Parse Protocol Buffer\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    feed.ParseFromString(response.content)\n",
    "    \n",
    "    # Convert to Dict for easier reading\n",
    "    feed_dict = MessageToDict(feed)\n",
    "    \n",
    "    print(f\"Successfully fetched {len(feed_dict.get('entity', []))} alerts.\")\n",
    "    \n",
    "    if feed_dict.get('entity'):\n",
    "        print(\"Sample Alert:\")\n",
    "        print(feed_dict['entity'][0])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7f737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing alerts for Route '1'...\n",
      "Found Active Alert: {'is_delay': 1, 'is_reroute': 0, 'is_suspension': 0, 'cause_police': 1, 'cause_medical': 0, 'cause_signal': 0, 'cause_mechanical': 0}\n",
      "\n",
      "Total Active Relevant Alerts: 1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def parse_alert_to_features(alert_entity, target_route_id=\"A\"):\n",
    "    \"\"\"\n",
    "    Parses a single GTFS-Realtime alert entity into model features.\n",
    "    Returns None if the alert is not relevant to the target route.\n",
    "    \"\"\"\n",
    "    alert = alert_entity.get('alert', {})\n",
    "    \n",
    "    # 1. Filter by Route\n",
    "    # Check if this alert applies to our target line\n",
    "    is_relevant = False\n",
    "    for entity in alert.get('informedEntity', []):\n",
    "        if entity.get('routeId') == target_route_id:\n",
    "            is_relevant = True\n",
    "            break\n",
    "    \n",
    "    if not is_relevant:\n",
    "        return None\n",
    "\n",
    "    # 2. Check Active Period\n",
    "    # Alerts often have start/end times. We only care if it's active NOW.\n",
    "    # (For historical training, we would check if it overlaps with the training window)\n",
    "    current_time = time.time()\n",
    "    is_active = False\n",
    "    active_periods = alert.get('activePeriod', [])\n",
    "    \n",
    "    if not active_periods:\n",
    "        # If no time specified, assume active\n",
    "        is_active = True\n",
    "    else:\n",
    "        for period in active_periods:\n",
    "            start = int(period.get('start', 0))\n",
    "            end = int(period.get('end', 9999999999)) # Default to far future\n",
    "            if start <= current_time <= end:\n",
    "                is_active = True\n",
    "                break\n",
    "    \n",
    "    if not is_active:\n",
    "        return None\n",
    "\n",
    "    # 3. Extract Semantics (Cause & Effect)\n",
    "    # Ideally, we use the 'cause' and 'effect' enums if provided.\n",
    "    # If missing (like in your sample), we fall back to keyword matching on the text.\n",
    "    \n",
    "    header_text = \"\"\n",
    "    if 'headerText' in alert and 'translation' in alert['headerText']:\n",
    "        # Get English text\n",
    "        for t in alert['headerText']['translation']:\n",
    "            if t.get('language') == 'en':\n",
    "                header_text = t.get('text', '').lower()\n",
    "                break\n",
    "    \n",
    "    # Simple Keyword Mapping (Feature Engineering)\n",
    "    features = {\n",
    "        \"is_delay\": 0,\n",
    "        \"is_reroute\": 0,\n",
    "        \"is_suspension\": 0,\n",
    "        \"cause_police\": 0,\n",
    "        \"cause_medical\": 0,\n",
    "        \"cause_signal\": 0,\n",
    "        \"cause_mechanical\": 0\n",
    "    }\n",
    "    \n",
    "    # Map Effects\n",
    "    if \"delay\" in header_text: features[\"is_delay\"] = 1\n",
    "    if \"reroute\" in header_text or \"running over\" in header_text: features[\"is_reroute\"] = 1\n",
    "    if \"suspended\" in header_text: features[\"is_suspension\"] = 1\n",
    "    \n",
    "    # Map Causes\n",
    "    if \"investigation\" in header_text or \"nypd\" in header_text or \"police\" in header_text: features[\"cause_police\"] = 1\n",
    "    if \"medical\" in header_text or \"ems\" in header_text: features[\"cause_medical\"] = 1\n",
    "    if \"signal\" in header_text: features[\"cause_signal\"] = 1\n",
    "    if \"mechanical\" in header_text or \"brakes\" in header_text: features[\"cause_mechanical\"] = 1\n",
    "\n",
    "    return features\n",
    "\n",
    "# --- Test with the fetched data ---\n",
    "# We'll look for alerts on the '1' line since that's what your sample showed, \n",
    "# just to verify the logic works.\n",
    "print(\"Parsing alerts for Route '1'...\")\n",
    "active_alerts_vector = []\n",
    "\n",
    "if 'feed_dict' in locals():\n",
    "    for entity in feed_dict.get('entity', []):\n",
    "        features = parse_alert_to_features(entity, target_route_id=\"1\")\n",
    "        if features:\n",
    "            print(f\"Found Active Alert: {features}\")\n",
    "            # In a real pipeline, we would aggregate these (e.g., take the max across all active alerts)\n",
    "            active_alerts_vector.append(features)\n",
    "            \n",
    "    print(f\"\\nTotal Active Relevant Alerts: {len(active_alerts_vector)}\")\n",
    "else:\n",
    "    print(\"feed_dict not found. Run the previous cell first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
