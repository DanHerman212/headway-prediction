{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTHENTICATION FOR COLAB\n",
    "# If you are running this locally, you can skip this.\n",
    "# If you are running in Colab, you MUST run this cell first.\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print(\"Authenticated successfully!\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab. Ensure your local environment is authenticated via 'gcloud auth application-default login'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383d47bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-forecasting\n",
      "  Downloading pytorch_forecasting-1.6.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy<=3.0.0 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from pytorch-forecasting) (2.4.1)\n",
      "Collecting torch!=2.0.1,<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
      "  Downloading torch-2.10.0-cp313-none-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting lightning<2.7.0,>=2.0.0 (from pytorch-forecasting)\n",
      "  Downloading lightning-2.6.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting scipy<2.0,>=1.8 (from pytorch-forecasting)\n",
      "  Using cached scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from pytorch-forecasting) (2.3.3)\n",
      "Collecting scikit-learn<2.0,>=1.2 (from pytorch-forecasting)\n",
      "  Using cached scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scikit-base<0.14.0 (from pytorch-forecasting)\n",
      "  Downloading scikit_base-0.13.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: PyYAML<8.0,>5.4 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from lightning<2.7.0,>=2.0.0->pytorch-forecasting) (6.0.3)\n",
      "Collecting fsspec<2027.0,>=2022.5.0 (from fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: packaging<27.0,>=20.0 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from lightning<2.7.0,>=2.0.0->pytorch-forecasting) (26.0)\n",
      "Collecting torchmetrics<3.0,>0.7.0 (from lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tqdm<6.0,>=4.57.0 (from lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from lightning<2.7.0,>=2.0.0->pytorch-forecasting) (4.15.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: setuptools in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting) (80.10.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.3)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn<2.0,>=1.2->pytorch-forecasting)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn<2.0,>=1.2->pytorch-forecasting)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting sympy>=1.13.3 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Downloading multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7.0,>=2.0.0->pytorch-forecasting) (3.11)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danherman/Desktop/headway-prediction/.venv/lib/python3.13/site-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.3)\n",
      "Downloading pytorch_forecasting-1.6.1-py3-none-any.whl (399 kB)\n",
      "Downloading lightning-2.6.0-py3-none-any.whl (845 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading scikit_base-0.13.1-py3-none-any.whl (159 kB)\n",
      "Using cached scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl (8.0 MB)\n",
      "Using cached scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl (20.1 MB)\n",
      "Downloading torch-2.10.0-cp313-none-macosx_11_0_arm64.whl (79.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
      "Downloading aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl (490 kB)\n",
      "Downloading multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Installing collected packages: mpmath, tqdm, threadpoolctl, sympy, scipy, scikit-base, propcache, networkx, multidict, lightning-utilities, joblib, jinja2, fsspec, frozenlist, filelock, attrs, aiohappyeyeballs, yarl, torch, scikit-learn, aiosignal, torchmetrics, aiohttp, pytorch-lightning, lightning, pytorch-forecasting\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [pytorch-forecasting]torch-forecasting]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 attrs-25.4.0 filelock-3.20.3 frozenlist-1.8.0 fsspec-2026.1.0 jinja2-3.1.6 joblib-1.5.3 lightning-2.6.0 lightning-utilities-0.15.2 mpmath-1.3.0 multidict-6.7.1 networkx-3.6.1 propcache-0.4.1 pytorch-forecasting-1.6.1 pytorch-lightning-2.6.0 scikit-base-0.13.1 scikit-learn-1.8.0 scipy-1.17.0 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.10.0 torchmetrics-1.8.2 tqdm-4.67.1 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-forecasting pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ebf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-forecasting pytorch-lightning\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline, QuantileLoss\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8487ccb",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We load the data from our staging area.\n",
    "*   **Key Requirement:** TFT requires a `time_idx` (integer step) and `group_ids` (series identifier).\n",
    "*   Our `group_ids` will be the `route_id` (e.g., A, C, E).\n",
    "*   Our `time_idx` must be continuous for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875180e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "# Read SQL Query from file\n",
    "# Assuming the notebook is running from the 'notebooks' directory\n",
    "sql_path = os.path.join(\"sql\", \"tft_training_data.sql\")\n",
    "\n",
    "with open(sql_path, \"r\") as f:\n",
    "    query = f.read()\n",
    "\n",
    "client = bigquery.Client(project=\"realtime-headway-prediction\")\n",
    "df = client.query(query).to_dataframe()\n",
    "\n",
    "# Convert Types\n",
    "df['arrival_time'] = pd.to_datetime(df['arrival_time'])\n",
    "df['hour_of_day'] = df['hour_of_day'].astype(float) # TFT expects Reals to be float\n",
    "df['day_of_week'] = df['day_of_week'].astype(str) # Categorical\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30678aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Rolling Statistics\n",
    "# 1. Route-Level Statistics (The \"A\" train context)\n",
    "indexer = df.groupby([\"route_id\", \"track\"])[\"service_headway\"]\n",
    "df[\"rolling_mean_10\"] = indexer.transform(lambda x: x.rolling(window=10, min_periods=1).mean())\n",
    "df[\"rolling_std_10\"] = indexer.transform(lambda x: x.rolling(window=10, min_periods=1).std()).fillna(0)\n",
    "df[\"rolling_max_20\"] = indexer.transform(lambda x: x.rolling(window=20, min_periods=1).max())\n",
    "\n",
    "# 2. Track-Level Statistics (The \"Invsisible Traffic\" context)\n",
    "# We sort by track first to ensure rolling excludes route partitioning\n",
    "df.sort_values(['track', 'arrival_time'], inplace=True)\n",
    "track_indexer = df.groupby(\"track\")[\"track_headway\"]\n",
    "df[\"rolling_track_mean_5\"] = track_indexer.transform(lambda x: x.rolling(window=5, min_periods=1).mean().fillna(0))\n",
    "\n",
    "# 3. Create Group ID\n",
    "df['group_id'] = df['route_id'] + \"_\" + df['track']\n",
    "\n",
    "# 4. Time Indexing & Time Delta\n",
    "# Sort by group to establish sequence\n",
    "df.sort_values(['group_id', 'arrival_time'], inplace=True)\n",
    "\n",
    "# Event-Based Indexing (Sequence Order)\n",
    "df['time_idx'] = df.groupby('group_id').cumcount()\n",
    "\n",
    "# Explicit Time Feature (Fixing the \"Time Distortion\")\n",
    "# This tells the model how much wall-clock time passed since the last event\n",
    "df[\"dt_since_prev\"] = df.groupby(\"group_id\")[\"arrival_time\"].diff().dt.total_seconds() / 60\n",
    "df[\"dt_since_prev\"] = df[\"dt_since_prev\"].fillna(0)\n",
    "\n",
    "print(\"Features Added:\")\n",
    "print(\"- Route Context: rolling_mean_10, rolling_std_10\")\n",
    "print(\"- Track Context: rolling_track_mean_5 (Congestion indicator)\")\n",
    "print(\"- Time Context: dt_since_prev (Wall-clock minutes per step)\")\n",
    "\n",
    "df[['arrival_time', 'group_id', 'time_idx', 'service_headway', 'dt_since_prev', 'track_headway']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22485f03",
   "metadata": {},
   "source": [
    "## 2. TFT Data Structure (TimeSeriesDataSet)\n",
    "\n",
    "This is the most critical part. We map our columns to TFT's input buckets.\n",
    "\n",
    "*   **time_idx**: The integer time step.\n",
    "*   **target**: `headway`\n",
    "*   **group_ids**: `['route_id', 'direction_id', 'stop_id']` (defines a unique time series).\n",
    "*   **static_categoricals**: `['route_id']` (Things that don't change).\n",
    "*   **time_varying_known_reals**: `['scheduled_headway', 'hour_of_day']` (We know the schedule in the future).\n",
    "*   **time_varying_unknown_reals**: `['headway', 'actual_delay']` (We only know these in the past)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aeb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition - adapt column names to your schema\n",
    "max_prediction_length = 3 \n",
    "max_encoder_length = 20\n",
    "\n",
    "# TRAIN/VAL SPLIT\n",
    "max_time_idx = df[\"time_idx\"].max()\n",
    "training_cutoff = int(max_time_idx * 0.8)\n",
    "\n",
    "# 1. Training Dataset - FULL VISIBILITY MODE\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"service_headway\",\n",
    "    group_ids=[\"group_id\"],\n",
    "    min_encoder_length=10, \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    \n",
    "    # Static variables \n",
    "    static_categoricals=[\"route_id\", \"track\"], \n",
    "    \n",
    "    # Known Future Inputs\n",
    "    time_varying_known_reals=[\"scheduled_headway\", \"hour_of_day\"],\n",
    "    time_varying_known_categoricals=[\"day_of_week\"],\n",
    "    \n",
    "    # Unknown Future Inputs - AUGMENTED\n",
    "    time_varying_unknown_reals=[\n",
    "        \"service_headway\",          # Target\n",
    "        \"rolling_mean_10\",          # Recent performance of THIS route\n",
    "        \"rolling_std_10\",           \n",
    "        \n",
    "        \"track_headway\",            # CRITICAL: Gap to ANY train in front\n",
    "        \"rolling_track_mean_5\",     # CRITICAL: Is the physical track congested?\n",
    "        \n",
    "        \"dt_since_prev\"             # CRITICAL: Explicit time duration of the step\n",
    "    ],\n",
    "    \n",
    "    # Standard Z-Score normalization\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"group_id\"], transformation=None\n",
    "    ), \n",
    "    \n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "# 2. Validation Dataset \n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training, \n",
    "    df, \n",
    "    predict=False, \n",
    "    stop_randomization=True,\n",
    "    min_prediction_idx=training_cutoff + 1\n",
    ")\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "print(\"Datasets Configured (Full Visibility Mode).\") \n",
    "print(f\"Features: {training.reals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b227f4",
   "metadata": {},
   "source": [
    "## 3. Training the Model\n",
    "\n",
    "We use PyTorch Lightning.\n",
    "*   **QuantileLoss**: Optimizes for the median (0.5) as well as the 10th and 90th percentiles. This gives us prediction intervals (e.g., \"Train is arriving in 5 mins +/- 1 min\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb55e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "try:\n",
    "    import lightning.pytorch as pl_new\n",
    "except ImportError:\n",
    "    pl_new = None\n",
    "\n",
    "# MODEL CONFIGURATION\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.01,\n",
    "    hidden_size=64,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    output_size=7,  \n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10, \n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# DIAGNOSTIC & FIX\n",
    "using_modern_pl = False\n",
    "if pl_new is not None and isinstance(tft, pl_new.LightningModule):\n",
    "    pl = pl_new\n",
    "    using_modern_pl = True\n",
    "elif isinstance(tft, pl.LightningModule):\n",
    "    pass\n",
    "else:\n",
    "    raise TypeError(\"Library Version Mismatch: Please Restart Runtime/Kernel.\")\n",
    "\n",
    "# TRAINER CONFIGURATION - FULL DATA MODE\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30, # Increased to allow convergence on full data\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1, \n",
    "    limit_train_batches=1.0, # CRITICAL: Use 100% of the data (remove \"handbrake\")\n",
    ")\n",
    "\n",
    "print(f\"Model Configured: Hidden Size=64, LR=0.01\")\n",
    "print(\"Training on 100% of batches (Handbrake removed).\")\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb061611",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Interpretability\n",
    "\n",
    "TFT's superpower is interpretability. We can plot:\n",
    "1.  **Variable Importance**: Which features matters most? (Schedule vs Past Delays).\n",
    "2.  **Attention Weights**: Is the model looking at the recent past or distant past?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada04607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the best model execution\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(f\"Loading best model from: {best_model_path}\")\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# 2. Get predictions on the validation set\n",
    "# mode=\"raw\" returns the full distribution (quantiles), not just the mean\n",
    "# API Fix: Handle cases where predict returns (output, x, index) vs (output, x)\n",
    "prediction_result = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "if isinstance(prediction_result, tuple) and len(prediction_result) >= 2:\n",
    "    raw_predictions = prediction_result[0]\n",
    "    x = prediction_result[1]\n",
    "    print(f\"Prediction returned {len(prediction_result)} items. Successfully unpacked.\")\n",
    "else:\n",
    "    # Fallback to standard unpacking (will crash if incorrect, but we hope the tuple check caught it)\n",
    "    raw_predictions, x = prediction_result\n",
    "\n",
    "# 3. INTERPRETATION: Variable Importance\n",
    "# This shows which features (e.g. 'scheduled_headway', 'rolling_mean') the model actually used.\n",
    "print(\"generating Variable Importance Plot...\")\n",
    "try:\n",
    "    interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "    best_tft.plot_interpretation(interpretation)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate interpretation plot: {e}\")\n",
    "\n",
    "# 4. VISUALIZATION: Real vs Predicted\n",
    "# We plot a few examples. The grey area represents the uncertainty (10th to 90th percentile).\n",
    "print(\"\\nPlotting example predictions (Grey cone = 10th-90th percentile confidence interval):\")\n",
    "# Plotting indices 0, 10, 20 just to see a variety\n",
    "for idx in [0, 10, 20]:  \n",
    "    try:\n",
    "        # Check if index is valid\n",
    "        if idx < x[\"decoder_target\"].shape[0]:\n",
    "            best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Index {idx} out of bounds for plotting.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting index {idx}: {e}\")\n",
    "\n",
    "print(\"\\nINTERPRETATION GUIDE:\")\n",
    "print(\"- Encoder Variables: What *past* information mattered most?\")\n",
    "print(\"- Decoder Variables: What *future* information (like schedule) helped most?\")\n",
    "print(\"- Static Variables: Did the Route ID matter?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
