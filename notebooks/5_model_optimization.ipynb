{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4iFL_Y7jG3qA",
   "metadata": {
    "id": "4iFL_Y7jG3qA"
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# === GPU Check ===\n",
    "print(\"üîç GPU Status:\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"   ‚úÖ Found {len(gpus)} GPU(s): {[gpu.name for gpu in gpus]}\")\n",
    "    # Enable memory growth to avoid OOM\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è No GPU found - training will be slow!\")\n",
    "    print(\"   In Colab: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "# === Mixed Precision: BFloat16 (A100 optimized) ===\n",
    "# BFloat16 has same dynamic range as Float32 (8-bit exponent)\n",
    "# - No loss scaling required\n",
    "# - Stable for recurrent networks (eliminates NaN issue)\n",
    "# - Native Tensor Core acceleration on A100\n",
    "from tensorflow.keras import mixed_precision\n",
    "if gpus:\n",
    "    try:\n",
    "        mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "        print(f\"\\n‚úÖ Mixed Precision: mixed_bfloat16 (A100 optimized)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è BFloat16 not available ({e}), falling back to float16\")\n",
    "        mixed_precision.set_global_policy('mixed_float16')\n",
    "    policy = mixed_precision.global_policy()\n",
    "    print(f\"   Compute dtype: {policy.compute_dtype}\")\n",
    "    print(f\"   Variable dtype: {policy.variable_dtype}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Mixed Precision skipped (no GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LCOcxhtZG6MN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1767729407264,
     "user": {
      "displayName": "Dan Herman",
      "userId": "12632515228691427055"
     },
     "user_tz": 300
    },
    "id": "LCOcxhtZG6MN",
    "outputId": "22683568-289c-4737-92de-98f1422e3653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Colab\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "added to sys.path: /content/drive/MyDrive/Colab Notebooks/headway-prediction\n",
      "Project Root: /content/drive/MyDrive/Colab Notebooks/headway-prediction\n"
     ]
    }
   ],
   "source": [
    "# environment configuration\n",
    "# check if running in colab\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "  from google.colab import drive\n",
    "  print(\"Running in Colab\")\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "  # EDIT THIS: Your exact folder path in Drive\n",
    "  PROJECT_ROOT = \"/content/drive/MyDrive/Colab Notebooks/headway-prediction\"\n",
    "else:\n",
    "    print(\"üíª Running in Local Environment\")\n",
    "    # Assuming notebook is in /notebooks, root is one level up\n",
    "    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# system setup path\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "  sys.path.append(PROJECT_ROOT)\n",
    "  print(f\"added to sys.path: {PROJECT_ROOT}\")\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pN-RNMkSHDiZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1767729410267,
     "user": {
      "displayName": "Dan Herman",
      "userId": "12632515228691427055"
     },
     "user_tz": 300
    },
    "id": "pN-RNMkSHDiZ",
    "outputId": "7e5f066e-3373-4fe9-b6f8-01b1e303088c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success: All custom 'src' modules imported.\n"
     ]
    }
   ],
   "source": [
    "# Validate Imports\n",
    "try:\n",
    "    from src.config import Config\n",
    "    from src.data.dataset import SubwayDataGenerator\n",
    "    from src.models.convlstm import ConvLSTM  # Class-based architecture\n",
    "    from src.training.trainer import Trainer\n",
    "    from src.evaluator import Evaluator\n",
    "    print(\"‚úÖ Success: All custom 'src' modules imported.\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå IMPORT ERROR: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l6G9YsokLQkC",
   "metadata": {
    "id": "l6G9YsokLQkC"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882CebtOLP64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1767729413901,
     "user": {
      "displayName": "Dan Herman",
      "userId": "12632515228691427055"
     },
     "user_tz": 300
    },
    "id": "882CebtOLP64",
    "outputId": "42b1d181-39f2-4b83-ebb0-c59acc0f6d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /content/drive/MyDrive/Colab Notebooks/headway-prediction/data\n",
      "Loading data from /content/drive/MyDrive/Colab Notebooks/headway-prediction/data...\n",
      "Headway Shape: (264222, 66, 2, 1)\n",
      "Schedule Shape: (264222, 2, 1)\n",
      "Raw max headway values: 30.0 min (should be ~30.0)\n",
      "\n",
      "Fitting RobustScaler on first 158533 steps\n",
      "Transforming Headway and Schedule Data\n",
      "Scaler saved to /content/drive/MyDrive/Colab Notebooks/headway-prediction/models/robust_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Data loading and scaling\n",
    "# Paper uses MinMax normalization to [0,1] (Section 3.1)\n",
    "\n",
    "config = Config()\n",
    "config.DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "print(f\"Loading data from {config.DATA_DIR}\")\n",
    "\n",
    "# 1. Instantiate data generator\n",
    "data_gen = SubwayDataGenerator(config)\n",
    "\n",
    "# 2. Load raw .npy files (no normalization - we'll use MinMaxScaler per paper)\n",
    "data_gen.load_data(normalize=False)\n",
    "print(f\"Raw max headway values: {data_gen.headway_data.max():.2f} min\")\n",
    "\n",
    "# 3. Fit MinMaxScaler (Paper Section 3.1: \"normalized to [0,1] using min-max scaling\")\n",
    "total_timesteps = len(data_gen.headway_data)\n",
    "train_limit = int(total_timesteps * 0.6)\n",
    "\n",
    "print(f\"\\nüìÑ Paper: 'headway values normalized to the interval [0, 1] using min-max scaling'\")\n",
    "print(f\"Fitting MinMaxScaler on first {train_limit} steps\")\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "flat_train = data_gen.headway_data[:train_limit].reshape(-1, 1)\n",
    "scaler.fit(flat_train)\n",
    "\n",
    "# 4. Transform All Data\n",
    "print(\"Transforming Headway and Schedule Data\")\n",
    "data_gen.headway_data = scaler.transform(data_gen.headway_data.reshape(-1, 1)).reshape(data_gen.headway_data.shape)\n",
    "data_gen.schedule_data = scaler.transform(data_gen.schedule_data.reshape(-1, 1)).reshape(data_gen.schedule_data.shape)\n",
    "\n",
    "# 5. Save scaler for inference\n",
    "scaler_path = os.path.join(PROJECT_ROOT, \"models\", \"minmax_scaler.pkl\")\n",
    "os.makedirs(os.path.dirname(scaler_path), exist_ok=True)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úÖ Scaler saved to {scaler_path}\")\n",
    "\n",
    "print(f\"\\nScaled data range: [{data_gen.headway_data.min():.4f}, {data_gen.headway_data.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T4QZ-e6KTszh",
   "metadata": {
    "id": "T4QZ-e6KTszh"
   },
   "source": [
    "# Baseline Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I3A-oEGpTsFb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1767729417897,
     "user": {
      "displayName": "Dan Herman",
      "userId": "12632515228691427055"
     },
     "user_tz": 300
    },
    "id": "I3A-oEGpTsFb",
    "outputId": "5733fad4-02ca-46c5-9e29-218b181d8e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Run Config --- \n",
      "lookback: 30\n",
      "batch: 64\n",
      "epochs: 20\n",
      "filters: 64\n",
      "\n",
      "creating datasets...\n",
      "Creating dataset from index 0 to 158533\n",
      "Creating dataset from index 158533 to 211377\n",
      "Creating dataset from index 211377 to 264177\n",
      "Input headway shape: (64, 30, 66, 2, 1)\n",
      "Target shape: (64, 15, 66, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "# Large batch size to saturate Tensor Cores and reduce kernel launch overhead\n",
    "# BFloat16 + unroll=True should stabilize training\n",
    "\n",
    "config.LOOKBACK_MINS = 30\n",
    "config.FORECAST_MINS = 15\n",
    "config.BATCH_SIZE = 256  # Large batch for A100 throughput (amortizes fixed overhead)\n",
    "config.EPOCHS = 100\n",
    "config.LEARNING_RATE = 0.001  # May need to scale with batch size\n",
    "\n",
    "print(f'--- Configuration ---')\n",
    "print(f'Lookback: {config.LOOKBACK_MINS} minutes')\n",
    "print(f'Forecast: {config.FORECAST_MINS} minutes')\n",
    "print(f'Batch Size: {config.BATCH_SIZE}')\n",
    "print(f'Epochs: {config.EPOCHS}')\n",
    "print(f'Learning Rate: {config.LEARNING_RATE}')\n",
    "\n",
    "# Create tf datasets (60% train, 20% val, 20% test)\n",
    "train_end = int(0.6 * total_timesteps)\n",
    "val_end = int(0.8 * total_timesteps)\n",
    "\n",
    "print(f\"\\nCreating datasets...\")\n",
    "train_ds = data_gen.make_dataset(start_index=0, end_index=train_end, shuffle=True)\n",
    "val_ds = data_gen.make_dataset(start_index=train_end, end_index=val_end, shuffle=False)\n",
    "test_ds = data_gen.make_dataset(start_index=val_end, end_index=None, shuffle=False)\n",
    "\n",
    "# Shape verification (critical sanity check!)\n",
    "print(\"\\nüîç Shape Verification:\")\n",
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"   headway_input:  {inputs['headway_input'].shape}  (expected: [batch, 30, 66, 2])\")\n",
    "    print(f\"   schedule_input: {inputs['schedule_input'].shape}  (expected: [batch, 15, 2])\")\n",
    "    print(f\"   target:         {targets.shape}  (expected: [batch, 15, 66, 2])\")\n",
    "    \n",
    "    # Validate shapes match model expectations\n",
    "    assert inputs['headway_input'].shape[1:] == (30, 66, 2), \"‚ùå headway_input shape mismatch!\"\n",
    "    assert inputs['schedule_input'].shape[1:] == (15, 2), \"‚ùå schedule_input shape mismatch!\"\n",
    "    assert targets.shape[1:] == (15, 66, 2), \"‚ùå target shape mismatch!\"\n",
    "    print(\"   ‚úÖ All shapes verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xDCAccOXVW53",
   "metadata": {
    "id": "xDCAccOXVW53"
   },
   "source": [
    "# Model Build and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-jvmAwj2VaPd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jvmAwj2VaPd",
    "outputId": "5678fd20-5714-4249-b4bb-d8bdc51723bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building V2 Architecture\n",
      "Starting Training...\n",
      "Epoch 1/20\n",
      "\u001b[1m2477/2477\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 197ms/step - loss: 0.1695 - mae: 0.4089 - mse: 0.3959 - val_loss: 0.1649 - val_mae: 0.3905 - val_mse: 0.3955 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m 145/2477\u001b[0m \u001b[32m‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m6:46\u001b[0m 175ms/step - loss: 0.1515 - mae: 0.3731 - mse: 0.3572"
     ]
    }
   ],
   "source": [
    "# Build and train using the Trainer module\n",
    "print(f\"\\nüèóÔ∏è Building Model...\")\n",
    "\n",
    "# Use ConvLSTM encoder-decoder architecture\n",
    "model_builder = ConvLSTM(config)\n",
    "model = model_builder.build_model()\n",
    "model.summary()\n",
    "\n",
    "# Calculate steps per epoch for CosineDecay LR schedule\n",
    "steps_per_epoch = train_end // config.BATCH_SIZE\n",
    "print(f\"\\nSteps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "# Use Trainer class for clean compilation and training\n",
    "checkpoint_dir = os.path.join(PROJECT_ROOT, \"models\")\n",
    "trainer = Trainer(model, config, checkpoint_dir=checkpoint_dir, steps_per_epoch=steps_per_epoch)\n",
    "trainer.compile_model()\n",
    "\n",
    "print(\"\\nüöÄ Starting Training...\")\n",
    "history = trainer.fit(\n",
    "    train_ds, \n",
    "    val_ds,\n",
    "    patience=20,  # Early stopping patience (paper uses 50)\n",
    "    reduce_lr_patience=7  # Reduce LR if no improvement for 7 epochs\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rpu1TCpAXc6b",
   "metadata": {
    "id": "rpu1TCpAXc6b"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T3UlzE0HXMPd",
   "metadata": {
    "id": "T3UlzE0HXMPd"
   },
   "outputs": [],
   "source": [
    "# Evaluate best model on independent TEST set\n",
    "# This is the held-out 20% that was never seen during training or validation\n",
    "from src.metrics import rmse_seconds, r_squared\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üß™ FINAL TEST SET EVALUATION (Independent Data)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best model from checkpoint using ConvLSTM's class method\n",
    "best_model_path = os.path.join(PROJECT_ROOT, \"models\", \"best_model.keras\")\n",
    "print(f\"\\nLoading best model from: {best_model_path}\")\n",
    "best_model = ConvLSTM.load_model(best_model_path)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_results = best_model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "# Extract metrics (order: loss, rmse_seconds, r_squared)\n",
    "test_loss = test_results[0]\n",
    "test_rmse_sec = test_results[1]\n",
    "test_r2 = test_results[2]\n",
    "\n",
    "# Also compute RMSE from loss for verification\n",
    "test_rmse_from_loss = np.sqrt(test_loss) * (scaler.data_max_[0] - scaler.data_min_[0]) * 60\n",
    "\n",
    "print(f\"\\nüìä Test Set Results:\")\n",
    "print(f\"   RMSE: {test_rmse_sec:.1f} seconds ({test_rmse_sec/60:.2f} minutes)\")\n",
    "print(f\"   R¬≤:   {test_r2:.4f}\")\n",
    "\n",
    "# Production readiness on TEST data\n",
    "print(f\"\\nüö¶ Production Readiness (on unseen test data):\")\n",
    "if test_rmse_sec <= 60:\n",
    "    print(f\"   ‚úÖ EXCELLENT - {test_rmse_sec:.1f}s RMSE suitable for real-time displays\")\n",
    "elif test_rmse_sec <= 90:\n",
    "    print(f\"   ‚úÖ GOOD - {test_rmse_sec:.1f}s RMSE suitable for trip planning\")\n",
    "elif test_rmse_sec <= 120:\n",
    "    print(f\"   ‚ö†Ô∏è ACCEPTABLE - {test_rmse_sec:.1f}s RMSE for general information\")\n",
    "else:\n",
    "    print(f\"   ‚ùå NEEDS WORK - {test_rmse_sec:.1f}s RMSE exceeds production threshold\")\n",
    "\n",
    "if test_r2 >= 0.95:\n",
    "    print(f\"   ‚úÖ R¬≤ = {test_r2:.4f} - Excellent explanatory power\")\n",
    "elif test_r2 >= 0.90:\n",
    "    print(f\"   ‚úÖ R¬≤ = {test_r2:.4f} - Good explanatory power\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è R¬≤ = {test_r2:.4f} - Consider model improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves and paper-style visualizations\n",
    "evaluator = Evaluator(config, scaler=scaler)\n",
    "\n",
    "# Save directory for plots\n",
    "save_dir = os.path.join(PROJECT_ROOT, \"images\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1. Training curves (RMSE and R¬≤)\n",
    "print(\"\\nüìà Training Curves:\")\n",
    "evaluator.plot_training_curves(history, save_path=os.path.join(save_dir, \"training_curves.png\"))\n",
    "\n",
    "# 2. Paper-style heatmap visualizations (Figure 7 style)\n",
    "print(\"\\nüó∫Ô∏è Spatiotemporal Prediction Visualization:\")\n",
    "evaluator.plot_spatiotemporal_prediction(\n",
    "    best_model, test_ds, \n",
    "    sample_idx=0, direction=0,\n",
    "    save_path=os.path.join(save_dir, \"prediction_northbound.png\")\n",
    ")\n",
    "evaluator.plot_spatiotemporal_prediction(\n",
    "    best_model, test_ds, \n",
    "    sample_idx=0, direction=1,\n",
    "    save_path=os.path.join(save_dir, \"prediction_southbound.png\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
