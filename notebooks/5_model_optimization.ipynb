{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5_model_optimization_v2.ipynb\n",
    "# Optimized Spatiotemporal Model Training\n",
    "# Architecture: ST-ConvNet V2 (Sequential Encoder + Asymmetric Schedule Processing)\n",
    "# Scaling: RobustScaler (Median/IQR)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import joblib # For saving the scaler\n",
    "\n",
    "# --- Environment Setup (Colab vs Local) ---\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    print(\"Detected Colab Environment. Mounting Drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # UPDATE THIS PATH to match your Google Drive folder structure\n",
    "    PROJECT_ROOT = \"/content/drive/MyDrive/headway-prediction\"\n",
    "    \n",
    "    # Add project root to system path so we can import src.config, src.models\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Detected Local Environment.\")\n",
    "    # Assumes notebook is in 'notebooks/' and project root is one level up\n",
    "    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Validate Imports from src (sanity check)\n",
    "try:\n",
    "    from src.config import Config\n",
    "    from src.models.st_covnet_v2 import HeadwayConvLSTM_V2\n",
    "    print(\"✅ Successfully imported 'src' modules.\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Failed to import 'src' modules: {e}\")\n",
    "    print(\"Please ensure PROJECT_ROOT points to the folder containing 'src/'\")\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Data Loading & Scaling ---\n",
    "from src.data.dataset import SubwayDataGenerator\n",
    "\n",
    "# Initialize Config & Generator\n",
    "config = Config()\n",
    "print(f\"Loading data from: {config.DATA_DIR}\")\n",
    "\n",
    "# Load Raw Data\n",
    "data_gen = SubwayDataGenerator(config)\n",
    "data_gen.load_data() \n",
    "# Now data_gen.headway_data contains raw minutes (e.g., 5.0, 12.0)\n",
    "\n",
    "# --- Robust Scaling Strategy ---\n",
    "# We must fit the scaler ONLY on the training set to avoid data leakage.\n",
    "# The RobustScaler centers data using the Median and scales using the IQR.\n",
    "# This makes it resilient to the massive delays (outliers) common in subways.\n",
    "\n",
    "total_timesteps = len(data_gen.headway_data)\n",
    "train_split_idx = int(total_timesteps * 0.7) # 70% Train\n",
    "\n",
    "print(f\"\\nTotal Timesteps: {total_timesteps}\")\n",
    "print(f\"Training Split Index: {train_split_idx}\")\n",
    "\n",
    "# 1. Fit Scaler on Training Data Only\n",
    "print(\"Fitting RobustScaler on training subset...\")\n",
    "scaler = RobustScaler()\n",
    "# Flatten to (Samples, 1) because Scaler expects 2D array\n",
    "train_subset = data_gen.headway_data[:train_split_idx].reshape(-1, 1)\n",
    "scaler.fit(train_subset)\n",
    "\n",
    "# 2. Transform the Entire Dataset (Headways)\n",
    "print(\"Transforming Headway data...\")\n",
    "# Transform -> Reshape back to (Time, Stations, Dir, 1)\n",
    "data_gen.headway_data = scaler.transform(data_gen.headway_data.reshape(-1, 1)).reshape(data_gen.headway_data.shape)\n",
    "\n",
    "# 3. Transform Schedule Data\n",
    "# Since 'Schedule' is also in minutes, we use the SAME scaler so the units match.\n",
    "print(\"Transforming Schedule data...\")\n",
    "data_gen.schedule_data = scaler.transform(data_gen.schedule_data.reshape(-1, 1)).reshape(data_gen.schedule_data.shape)\n",
    "\n",
    "# 4. Save Scaler for later Inference/Evaluation\n",
    "scaler_path = os.path.join(PROJECT_ROOT, \"models\", \"robust_scaler.pkl\")\n",
    "# Ensure directory exists (in case 'models' folder is missing in Drive)\n",
    "os.makedirs(os.path.dirname(scaler_path), exist_ok=True)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"✅ Scaler saved to {scaler_path}\")\n",
    "\n",
    "# 5. Validation Stats\n",
    "print(\"\\n--- Scaled Data Statistics (should be centered ~0) ---\")\n",
    "print(f\"Mean: {np.mean(data_gen.headway_data):.2f}\")\n",
    "print(f\"Std Dev: {np.std(data_gen.headway_data):.2f}\")\n",
    "print(f\"Min: {np.min(data_gen.headway_data):.2f}\")\n",
    "print(f\"Max: {np.max(data_gen.headway_data):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
